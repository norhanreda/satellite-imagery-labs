{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Students Information\n","\n","Please enter the names and IDs of the two students below:\n","\n","1. **Name**: [Norhan Reda Abdelwahed Ahmed]  \n","   **ID**: `9203639` \n","\n","2. **Name**: [Hoda Gamal Hamouda Ismail]  \n","   **ID**: `9203673` \n"]},{"cell_type":"markdown","metadata":{},"source":["## Students Instructions\n","\n","This is your first graded lab assignment, as you put the work you have studied in the lectures in action, please take this opportunity to enhance your understanding of the concepts and hone your skills. As you work on your assignment, please keep the following instructions in mind:\n","\n","- Clearly state your personal information where indicated.\n","- Be ready with your work before the time of the next discussion slot in the schedule.\n","- Plagiarism will be met with penalties, refrain from copying any answers to make the most out of the assignment. If any signs of plagiarism are detected, actions will be taken.\n","- It is acceptable to share the workload of the assignment bearing the discussion in mind.\n","- Feel free to [reach out](mailto:cmpsy27@gmail.com) if there were any ambiguities or post on the classroom."]},{"cell_type":"markdown","metadata":{},"source":["## Submission Instructions\n","\n","To ensure a smooth evaluation process, please follow these steps for submitting your work:\n","\n","1. **Prepare Your Submission:** Alongside your main notebook, include any additional files that are necessary for running the notebook successfully. This might include data files, images, or supplementary scripts.\n","\n","2. **Rename Your Files:** Before submission, please rename your notebook to reflect the IDs of the two students working on this project. The format should be `ID1_ID2`, where `ID1` and `ID2` are the student IDs. For example, if the student IDs are `9123456` and `9876543`, then your notebook should be named `9123456_9876543.ipynb`.\n","\n","3. **Check for Completeness:** Ensure that all required tasks are completed and that the notebook runs from start to finish without errors. This step is crucial for a smooth evaluation.\n","\n","4. **Submit Your Work:** Once everything is in order, submit your notebook and any additional files via the designated submission link on Google Classroom **(code: 2yj6e24)**. Make sure you meet the submission deadline to avoid any late penalties.\n","5. Please, note that the same student should submit the assignments for the pair throughout the semester.\n","\n","By following these instructions carefully, you help us in evaluating your work efficiently and fairly **and any failure to adhere to these guidelines can affect your grades**. If you encounter any difficulties or have questions about the submission process, please reach out as soon as possible.\n","\n","We look forward to seeing your completed projects and wish you the best of luck!\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","\n","\n","## Installation Instructions\n","\n","In this lab assignment, we require additional Python libraries for scientific mathematics, particularly in the context of machine learning (ML) and satellite image analysis. To fulfill these requirements, we need to install Scikit-learn and Scikit-image. \n","1. Install Scikit-learn  \n","Scikit-learn (Sklearn) is a powerful Python library for ML tasks, offering various algorithms for classification, regression, clustering, and model evaluation. It is extensively used for analyzing satellite imagery, enabling tasks such as land cover classification and environmental parameter prediction. On the other hand, Scikit-image (Skimage) provides comprehensive tools for image processing and computer vision, facilitating tasks such as image preprocessing, feature extraction, and segmentation. These libraries are essential for extracting valuable insights from satellite images and conducting advanced analysis in scientific computing and research domains.\n","```bash\n","pip install scikit-learn scikit-image\n","```\n"]},{"cell_type":"markdown","metadata":{},"source":["> **Note:** You are allowed to install any other necessary libraries you deem useful for solving the lab. Please ensure that any additional libraries are compatible with the project requirements and are properly documented in your submission.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Maximum Likelihood Estimator (MLE) Classifier\n","The Maximum Likelihood Estimator (MLE) is a fundamental statistical approach used to infer the parameters of a given distribution that are most likely to result in the observed data. In the context of image classification, MLE helps to quantify the probability of observing the data within each predefined class based on their distinct statistical properties. This method is highly effective for classifying images into categories by comparing the likelihoods of the data under different model parameters, enabling the most probable class assignment.\n","\n","1. **Calculate Class Priors**: Estimate the probability of each class based on the training dataset. This is expressed as:\n","   $$\n","   P(C_k) = \\frac{N_k}{N}\n","   $$\n","   where \\(N_k\\) is the number of samples of class \\(k\\) and \\(N\\) is the total number of samples.\n","\n","2. **Estimate Class-specific Parameters**: For each class, estimate parameters such as the mean \\(\\mu_k\\) and covariance \\(\\Sigma_k\\) of features that describe the distribution of the data:\n","   $$\n","   \\mu_k = \\frac{1}{N_k} \\sum_{x \\in C_k} x\n","   $$\n","   $$\n","   \\Sigma_k = \\frac{1}{N_k} \\sum_{x \\in C_k} (x - \\mu_k)(x - \\mu_k)^T\n","   $$\n","\n","3. **Compute Likelihoods**: For a given test instance \\(x\\), compute the likelihood of that instance belonging to each class using the estimated parameters:\n","   $$\n","   p(x | C_k) = \\frac{1}{(2\\pi)^{d/2} |\\Sigma_k|^{1/2}} \\exp\\left(-\\frac{1}{2} (x - \\mu_k)^T \\Sigma_k^{-1} (x - \\mu_k)\\right)\n","   $$\n","\n","4. **Classify Based on Maximum Likelihood**: Assign the class label to each test instance based on the highest likelihood, which can be calculated as:\n","   $$\n","   \\hat{y} = \\arg\\max_{k} P(C_k) \\cdot p(x | C_k)\n","   $$\n","\n","The Naive Bayes classifier is perhaps the most well-known application of the Maximum Likelihood Estimator principle in classification tasks. It assumes that the features in each class are independent, simplifying the computation of likelihoods. While Naive Bayes is popular for its simplicity and efficiency, it is not the only technique that leverages the MLE approach. Other classical alternatives include Logistic Regression, which applies MLE to estimate the parameters that best predict categorical outcomes, and Gaussian Mixture Models, which use MLE to estimate the parameters of multiple Gaussian distributions within the data. Students are encouraged to explore these models to gain a deeper understanding of statistical estimation techniques.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Req- Image Classification for EuroSATallBands\n","Image classification is a key challenge in satellite imaging and remote sensing. As discussed in the lecture, this task is typically conducted on a pixel-wise basis because a single image can contain multiple textural elements of different celestial features. However, for this specific assignment, we will focus on identifying the dominant phenomena in the image as the basis for classification.\n","\n","- **Load the Images**: Load the images of the EuroSAT dataset that belong to the **residential**, **river**, and **forest** classes.\n","\n","- **Split the Dataset**: Split the dataset such that 10% of each class is used as testing data, and the remainder is used for training your classifier. Use the indices provided by `np.random.choice` with seed set to `27`. **Code is provided do not change it**.\n","\n","- **Feature Extraction**: Extract suitable features from the images that you think might be relevant in distinguishing each class from the others. Keep in mind the curse of dimensionality when selecting features.\n","\n","- **Implement a Maximum Likelihood Estimator (MLE)**: Implement a Maximum Likelihood Estimator (MLE) based on your training data. \n","- **Report Accuracy and Average F1 Score**: After testing your classifier on the test set, report the **Accuracy** and **Average F1 Score** of your model.\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Add your libraries here\n","import numpy as np\n","from skimage import io\n","import os\n","import numpy as np\n","from sklearn.metrics import confusion_matrix, accuracy_score, f1_score,ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","from sklearn.decomposition import PCA\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# DO NOT CHANGE THIS CELL\n","## Training set indices.\n","np.random.seed(27)  # Set random seed for reproducibility\n","\n","# Randomly select indices for the test sets for each class\n","residential_test_indices = np.random.choice(np.arange(3000), size=300, replace=False)\n","forest_test_indices = np.random.choice(np.arange(3000), size=300, replace=False)\n","river_test_indices = np.random.choice(np.arange(2500), size=250, replace=False)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Load the Images"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(3000, 4096, 13)\n"]}],"source":["dataset_folder = \"D:/Astudy/fourth year/second term/satellite imagery/dataset/EuroSATallBands/EuroSATallBands/ds/images/remote_sensing/otherDatasets/sentinel_2/tif\" \n","classes = [\"Residential\", \"River\", \"Forest\"]\n","images_by_class = {}\n","my_img = None\n","residual_labels =[]\n","river_labels = []\n","forest_labels = []\n","\n","for class_name in classes:\n","\n","    class_folder = os.path.join(dataset_folder, class_name)\n","    if os.path.exists(class_folder):\n","        \n","        images_by_class[class_name] = []\n","        for image_file in os.listdir(class_folder):\n","            \n","            image_path = os.path.join(class_folder, image_file)\n","            image = io.imread(image_path)\n","            # my_img = image\n","            image = image.reshape(image.shape[0] * image.shape[1], image.shape[2])\n","        \n","            \n","            \n","            images_by_class[class_name].append(image)\n","            if class_name == \"Residential\":\n","                residual_labels.append(\"Residential\")\n","            elif class_name == \"River\":\n","                river_labels.append(\"River\")\n","            elif   class_name == \"Forest\": \n","                forest_labels.append(\"Forest\")\n","                \n","\n","residential_images = np.array(images_by_class[\"Residential\"])\n","\n","river_images = np.array(images_by_class[\"River\"])\n","\n","forest_images = np.array(images_by_class[\"Forest\"])\n","\n","\n","print(residential_images.shape)\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["3000\n","2500\n","3000\n"]}],"source":["print(len(residual_labels))\n","print(len(river_labels))\n","print(len(forest_labels))"]},{"cell_type":"markdown","metadata":{},"source":[" # Split the Dataset"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["3000\n","2500\n","3000\n"]},{"name":"stdout","output_type":"stream","text":["(2700, 4096, 13)\n","(2250, 4096, 13)\n","(2700, 4096, 13)\n"]}],"source":["print(len(residential_images))\n","print(len(river_images))\n","print(len(forest_images))\n","\n","\n","\n","# print(residential_test_indices)\n","test_residual = residential_images[residential_test_indices]\n","test_river = river_images[river_test_indices]\n","test_forest =  forest_images[forest_test_indices]\n","\n","# print(test_residual)\n","# Generate the training indices by excluding the test indices\n","residential_training_indices = np.setdiff1d(np.arange(3000), residential_test_indices)\n","forest_training_indices = np.setdiff1d(np.arange(3000), forest_test_indices)\n","river_training_indices = np.setdiff1d(np.arange(2500), river_test_indices)\n","\n","train_residual = residential_images[residential_training_indices]\n","train_river = river_images[river_training_indices]\n","train_forest =forest_images[forest_training_indices]\n","\n","residual_labels = np.array(residual_labels)\n","river_labels = np.array(river_labels)\n","forest_labels = np.array(forest_labels)\n","\n","test_residual_labels = residual_labels[residential_test_indices]\n","test_river_labels = river_labels[river_test_indices]\n","test_forest_labels =  forest_labels[forest_test_indices]\n","\n","train_residual_labels = residual_labels[residential_training_indices]\n","train_river_labels = river_labels[river_training_indices]\n","train_forest_labels =forest_labels[forest_training_indices]\n","\n","print(train_residual.shape)\n","print(train_river.shape)\n","print(train_forest.shape)\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2700\n","(2250, 4096, 13)\n","(2700, 4096, 13)\n"]}],"source":["print(train_residual.shape[0])\n","print(train_river.shape)\n","print(train_forest.shape)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Feature Extraction"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"]},{"cell_type":"markdown","metadata":{},"source":["# Implement a Maximum Likelihood Estimator (MLE)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(7650, 53248)\n","(7650,)\n","(850, 53248)\n","(850,)\n","accuracy =  91.05882352941177\n"]}],"source":["\n","from sklearn.naive_bayes import GaussianNB\n","train_data = np.concatenate((train_residual,train_river,train_forest), axis=0)\n","train_labels = np.concatenate((train_residual_labels,train_river_labels ,train_forest_labels), axis=0)\n","\n","test_data = np.concatenate((test_residual,test_river,test_forest), axis=0)\n","test_labels = np.concatenate((test_residual_labels,test_river_labels ,test_forest_labels), axis=0)\n","train_data=train_data.reshape(train_data.shape[0],-1)\n","test_data=test_data.reshape(test_data.shape[0],-1)\n","\n","\n","print(train_data.shape)\n","print(train_labels.shape)\n","\n","print(test_data.shape)\n","print(test_labels.shape)\n","\n","\n","clf = GaussianNB()\n","clf.fit(train_data,train_labels)\n","predictions = clf.predict(test_data)\n","\n","accuracy = accuracy_score(test_labels,predictions)*100\n","print(\"accuracy = \",accuracy)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(7650, 53248)\n","(7650,)\n","(850, 53248)\n","(850,)\n","accuracy =  95.41176470588235\n"]}],"source":["\n","from sklearn.naive_bayes import GaussianNB\n","train_data = np.concatenate((train_residual,train_river,train_forest), axis=0)\n","train_labels = np.concatenate((train_residual_labels,train_river_labels ,train_forest_labels), axis=0)\n","\n","test_data = np.concatenate((test_residual,test_river,test_forest), axis=0)\n","test_labels = np.concatenate((test_residual_labels,test_river_labels ,test_forest_labels), axis=0)\n","train_data=train_data.reshape(train_data.shape[0],-1)\n","test_data=test_data.reshape(test_data.shape[0],-1)\n","\n","\n","print(train_data.shape)\n","print(train_labels.shape)\n","\n","print(test_data.shape)\n","print(test_labels.shape)\n","\n","pca = PCA(n_components=30)\n","train_data = pca.fit_transform(train_data)\n","test_data=pca.transform(test_data)\n","\n","clf = GaussianNB()\n","clf.fit(train_data,train_labels)\n","predictions = clf.predict(test_data)\n","\n","accuracy = accuracy_score(test_labels,predictions)*100\n","print(\"accuracy = \",accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['Forest' 'Forest' 'Forest' ... 'Forest' 'Forest' 'Forest']\n"]}],"source":["print(forest_labels)"]},{"cell_type":"markdown","metadata":{},"source":["## Submission Instructions\n","\n","To ensure a smooth evaluation process, please follow these steps for submitting your work:\n","\n","1. **Prepare Your Submission:** Alongside your main notebook, include any additional files that are necessary for running the notebook successfully. This might include data files, images, or supplementary scripts.\n","\n","2. **Rename Your Files:** Before submission, please rename your notebook to reflect the IDs of the two students working on this project. The format should be `ID1_ID2`, where `ID1` and `ID2` are the student IDs. For example, if the student IDs are `9123456` and `9876543`, then your notebook should be named `9123456_9876543.ipynb`.\n","\n","3. **Check for Completeness:** Ensure that all required tasks are completed and that the notebook runs from start to finish without errors. This step is crucial for a smooth evaluation.\n","\n","4. **Submit Your Work:** Once everything is in order, submit your notebook and any additional files via the designated submission link on Google Classroom **(code: 2yj6e24)**. Make sure you meet the submission deadline to avoid any late penalties.\n","5. Please, note that the same student should submit the assignments for the pair throughout the semester.\n","\n","By following these instructions carefully, you help us in evaluating your work efficiently and fairly **and any failure to adhere to these guidelines can affect your grades**. If you encounter any difficulties or have questions about the submission process, please reach out as soon as possible.\n","\n","We look forward to seeing your completed projects and wish you the best of luck!\n"]},{"cell_type":"markdown","metadata":{},"source":["# Report Accuracy and Average F1 Score"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["### Grading Rubric (Total: 10 Marks)\n","\n","The lab is graded based on the following criteria:\n","\n","1. **Data Loading and Preparation (2 Marks)**\n","   - Correctly loads images for the residential, river, and forest classes. (0.5 Marks)\n","   - Accurately splits the dataset into training and testing subsets and clearly shows this split. (1.5 Marks)\n","\n","2. **Feature Extraction (2 Marks)**\n","   - Implements feature extraction appropriately, considering the curse of dimensionality. (1 Mark)\n","   - Extracts and justifies the selection of features relevant to distinguishing the classes. (1 Mark)\n","\n","3. **Implementation of MLE Classifier (3 Marks)**\n","   - Correctly calculates and clearly shows class priors and class-specific parameters. (1 Mark)\n","   - Accurately computes likelihoods using the likelihood equation (probability density function) and classifies based on maximum likelihood. Must clearly show these calculations and explain the choice of likelihood equation. (2 Marks)\n","\n","4. **Model Evaluation and Understanding (3 Marks)**\n","   - Shows **confusion matrix** and correctly calculates and clearly shows the calculations for Accuracy and Average F1 Score. (1 Mark)\n","   - **Comparison amongst your peers.** Compares the model's performance against those of peers to identify strengths and areas for improvement. (2 Marks)\n","\n","Each section of the lab will be evaluated on completeness, and correctness in approach and analysis. Part of the rubric also includes the student's ability to explain and justify their choices and results.\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
